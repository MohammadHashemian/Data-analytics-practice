{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPARK_RAPIDS_PLUGIN_JAR=/opt/spark/jars/rapids-4-spark_2.13-24.04.1.jar\n"
     ]
    }
   ],
   "source": [
    "%env SPARK_RAPIDS_PLUGIN_JAR=/opt/spark/jars/rapids-4-spark_2.13-24.04.1.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Spark session...\n",
      "Session started\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "\n",
    "spark_rapids:str = os.getenv(\"SPARK_RAPIDS_PLUGIN_JAR\")\n",
    "\n",
    "# SPARK SESSION CONFIGURATION\n",
    "print(\"Running Spark session...\")\n",
    "session_builder = SparkSession.Builder() \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Learning Spark\") \\\n",
    "    .config(\"spark.ui.enabled\", True) \\\n",
    "    .config(\"spark.driver.bindAddress\", \"localhost\") \\\n",
    "    .config(\"spark.ui.port\", \"8080\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .config(\"spark.executor.memory\", \"10g\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", spark_rapids) \\\n",
    "    .config(\"spark.plugins\", \"com.nvidia.spark.SQLPlugin\") \\\n",
    "    .config(\"spark.rapids.memory.gpu.pooling.enabled\", True) \\\n",
    "    .config(\"spark.rapids.sql.enabled\", True) \\\n",
    "    .config(\"spark.rapids.sql.explain\", \"NONE\")\n",
    "spark = session_builder.getOrCreate()\n",
    "print(\"Session started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_excel = os.listdir(\"datasets-private/amarnameh-excel\")\n",
    "datasets_csv = sorted(os.listdir(\"datasets-private/amarnameh-csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading: 1398.csv\n",
      "---- Done ----\n",
      "[INFO] Reading: 1399.csv\n",
      "---- Done ----\n",
      "[INFO] Reading: 1400.csv\n",
      "---- Done ----\n",
      "[INFO] Reading: 1401.csv\n",
      "---- Done ----\n",
      "[INFO] Reading: 1402.csv\n",
      "---- Done ----\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "dataframes: dict[int, DataFrame] = {}\n",
    "\n",
    "for file_name in datasets_csv:\n",
    "    print(f\"[INFO] Reading: {str(file_name)}\")\n",
    "    filePath = f\"datasets-private/amarnameh-csv/{file_name}\"\n",
    "    df = spark.read.csv(header=True, path=filePath, inferSchema=True)\n",
    "    df_name = file_name.rstrip(\".csv\")\n",
    "    dataframes.update({int(df_name): df})\n",
    "    print(\"---- Done ----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~ Dataset[1398]: ~~~~~~~~\n",
      "----> Contains: 36999 Rows\n",
      "----> Headers Len: 27\n",
      "تولید کننده / وارد کننده\n",
      "صاحب پروانه\n",
      "توزیع کننده\n",
      "کد فرآورده\n",
      "کد ATC\n",
      "نام انگلیسی فرآورده\n",
      "نام فارسی فرآورده\n",
      "نام ژنریک\n",
      "Column1\n",
      "کد ژنریک\n",
      "تولیدی/وارداتی\n",
      "فوریتی/غیرفوریتی\n",
      "نوع فرآورده\n",
      "نام انگلیسی فهرست\n",
      "کد ATC سطح1\n",
      "عنوان ATC سطح 1\n",
      "کد ATC سطح 2\n",
      "عنوان ATC سطح 2\n",
      "کد ATC سطح 3\n",
      "عنوان ATC سطح 3\n",
      "کد ATC سطح 4\n",
      "عنوان ATC سطح 4\n",
      "حجم فروش\n",
      "تعداد در بسته\n",
      " فروش عددی \n",
      " فروش ریالی \n",
      "_c26\n",
      "~~~~~~~~ Dataset[1399]: ~~~~~~~~\n",
      "----> Contains: 1048575 Rows\n",
      "----> Headers Len: 20\n",
      "صاحب پروانه\n",
      "توزیع کننده\n",
      "IRC\n",
      "نام فرآورده (برند)\n",
      "تولیدی/وارداتی\n",
      "OTC\n",
      "بیولوژیک\n",
      "کشور تولید کننده\n",
      "تحت لیسانس\n",
      "111\n",
      "نام ژنریک\n",
      "فرآورده\n",
      "کد ژنریک\n",
      "ماده موثره\n",
      "ATC Code\n",
      " تعداد فروش (بسته) \n",
      " تعداد در بسته \n",
      " فروش عددی  \n",
      " فروش ریالی مصرف کننده  \n",
      "_c19\n",
      "~~~~~~~~ Dataset[1400]: ~~~~~~~~\n",
      "----> Contains: 52445 Rows\n",
      "----> Headers Len: 19\n",
      "نام شرکت تولید کننده\n",
      "نام شرکت تامین کننده\n",
      "نام صاحب برند\n",
      "توزیع کننده\n",
      "کشور تولید  کننده\n",
      "نام برند\n",
      "نام لاتین برند\n",
      "نام ژنریک\n",
      "نام ماده موثره\n",
      " تعداد فروش (بسته) \n",
      " تعداد در بسته \n",
      " فروش عددی \n",
      " فروش ریالی مصرف کننده \n",
      "کد ژنریک\n",
      "OTC\n",
      "بیولوژیک\n",
      "ATC Code\n",
      "_c17\n",
      "_c18\n",
      "~~~~~~~~ Dataset[1401]: ~~~~~~~~\n",
      "----> Contains: 125484 Rows\n",
      "----> Headers Len: 26\n",
      "تولید کننده / وارد کننده\n",
      "صاحب پروانه\n",
      "توزیع کننده\n",
      "کد فرآورده\n",
      "کد ATC\n",
      "نام انگلیسی فرآورده\n",
      "نام فارسی فرآورده\n",
      "کد ژنریک\n",
      "نام ژنریک\n",
      "تولیدی/وارداتی\n",
      "فوریتی/غیرفوریتی\n",
      "نوع فرآورده\n",
      "نام انگلیسی فهرست\n",
      "کد ATC سطح1\n",
      "عنوان ATC سطح 1\n",
      "کد ATC سطح 2\n",
      "عنوان ATC سطح 2\n",
      "کد ATC سطح 3\n",
      "عنوان ATC سطح 3\n",
      "کد ATC سطح 4\n",
      "عنوان ATC سطح 4\n",
      "حجم فروش\n",
      "ارزش ریالی (مصرف کننده)\n",
      "ارزش ریالی (توزیع کننده)\n",
      "ارزش ریالی (داروخانه)\n",
      "ماه شمسی\n",
      "~~~~~~~~ Dataset[1402]: ~~~~~~~~\n",
      "----> Contains: 107213 Rows\n",
      "----> Headers Len: 26\n",
      "تولید کننده / وارد کننده\n",
      "صاحب پروانه\n",
      "توزیع کننده\n",
      "کد فرآورده\n",
      "کد ATC\n",
      "نام انگلیسی فرآورده\n",
      "نام فارسی فرآورده\n",
      "کد ژنریک\n",
      "نام ژنریک\n",
      "تولیدی/وارداتی\n",
      "فوریتی/غیرفوریتی\n",
      "نوع فرآورده\n",
      "نام انگلیسی فهرست\n",
      "کد ATC سطح1\n",
      "عنوان ATC سطح 1\n",
      "کد ATC سطح 2\n",
      "عنوان ATC سطح 2\n",
      "کد ATC سطح 3\n",
      "عنوان ATC سطح 3\n",
      "کد ATC سطح 4\n",
      "عنوان ATC سطح 4\n",
      "حجم فروش\n",
      "ارزش ریالی (مصرف کننده)\n",
      "ارزش ریالی (توزیع کننده)\n",
      "ارزش ریالی (داروخانه)\n",
      "ماه شمسی\n"
     ]
    }
   ],
   "source": [
    "for df_name in dataframes:\n",
    "    df = dataframes.get(df_name)\n",
    "    print(f\"~~~~~~~~ Dataset[{df_name}]: ~~~~~~~~\")\n",
    "    print(f'----> Contains: {df.count()} Rows')\n",
    "    print(f\"----> Headers Len: {len(df.columns)}\")\n",
    "    for i in range(len(df.columns)):\n",
    "        print(df.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing...\n",
      "+-------------+--------+---------------------------------+\n",
      "|brand_owner  |atc_code|en_name                          |\n",
      "+-------------+--------+---------------------------------+\n",
      "|داروسازی امین|N03AX16 |PREGABALIN   CAPSULE ORAL 50 mg  |\n",
      "+-------------+--------+---------------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "+---------------+--------+---------------------------------------+\n",
      "|brand_owner    |atc_code|en_name                                |\n",
      "+---------------+--------+---------------------------------------+\n",
      "|اکترو خاورمیانه|L02BX03 |ABIRATERONE ACTE   TABLET ORAL 250 mg  |\n",
      "+---------------+--------+---------------------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "+-----------+--------+--------------------------------+\n",
      "|brand_owner|atc_code|en_name                         |\n",
      "+-----------+--------+--------------------------------+\n",
      "|اکتوورکو   |J05AX   |FAVIPIRAVIR   TABLET ORAL 200 mg|\n",
      "+-----------+--------+--------------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "+-----------------+--------+------------------------------------------------------------------------------------------------------------+\n",
      "|brand_owner      |atc_code|en_name                                                                                                     |\n",
      "+-----------------+--------+------------------------------------------------------------------------------------------------------------+\n",
      "|یارا طب خاورمیانه|H01CB02 |SANDOSTATIN LAR 20MG AMP   INJECTION, POWDER, LYOPHILIZED, FOR SUSPENSION, EXTENDED RELEASE PARENTERAL 20 mg|\n",
      "+-----------------+--------+------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "+--------------+--------+------------------------------+\n",
      "|brand_owner   |atc_code|en_name                       |\n",
      "+--------------+--------+------------------------------+\n",
      "|دارو سازی حکیم|J01AA07 |TETRAKIM   CAPSULE ORAL 250 mg|\n",
      "+--------------+--------+------------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "schema = [\"atc_code\", \"brand_owner\", \"drug_generic_name\", \"type\"]\n",
    "\n",
    "print(\"Normalizing...\")\n",
    "df_1398 = dataframes.get(\"1398\")\n",
    "df_1399 = dataframes.get(\"1399\")\n",
    "df_1400 = dataframes.get(\"1400\")\n",
    "df_1401 = dataframes.get(\"1401\")\n",
    "df_1402 = dataframes.get(\"1402\")\n",
    "\n",
    "df_1398 = df_1398.withColumnsRenamed({\"صاحب پروانه\": \"brand_owner\", \"کد ATC\": \"atc_code\", \"نام انگلیسی فرآورده\": \"en_name\"}) \\\n",
    "                            .select([\"brand_owner\", \"atc_code\", \"en_name\"])\n",
    "df_1399 = df_1399.withColumnsRenamed({\"صاحب پروانه\":\"brand_owner\", \"ATC Code\": \"atc_code\", \"نام فرآورده (برند)\": \"en_name\"}) \\\n",
    "                            .select([\"brand_owner\", \"atc_code\", \"en_name\"])\n",
    "df_1400 = df_1400.withColumnsRenamed({\"نام صاحب برند\": \"brand_owner\", \"ATC Code\": \"atc_code\", \"نام لاتین برند\": \"en_name\"}) \\\n",
    "                            .select([\"brand_owner\",\"atc_code\", \"en_name\"])\n",
    "df_1401 = df_1401.withColumnsRenamed({\"صاحب پروانه\" : \"brand_owner\", \"کد ATC\": \"atc_code\" , \"نام انگلیسی فرآورده\": \"en_name\"}) \\\n",
    "                            .select([\"brand_owner\", \"atc_code\", \"en_name\"])\n",
    "df_1402 = df_1402.withColumnsRenamed({\"صاحب پروانه\" : \"brand_owner\", \"کد ATC\": \"atc_code\", \"نام انگلیسی فرآورده\": \"en_name\"}) \\\n",
    "                            .select([\"brand_owner\", \"atc_code\", \"en_name\"])\n",
    "dataframes.update({\"1398\": df_1398, \"1399\":df_1399,  \"1400\": df_1400, \"1401\": df_1401, \"1402\": df_1402})\n",
    "for df_year in dataframes:\n",
    "    print(dataframes.get(df_year).show(truncate=False, n=1))\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the dataset...\n",
      "Completed\n",
      "+--------+----------------------------------------------------------+\n",
      "|atc_code|label                                                     |\n",
      "+--------+----------------------------------------------------------+\n",
      "|J01GB06 |AMIKACIN (AS SULFATE) INJECTION PARENTERAL 250 mg/1mL 2 mL|\n",
      "|J01GB06 |AMIKACIN (AS SULFATE) INJECTION PARENTERAL 50 mg/1mL 2 mL |\n",
      "+--------+----------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "antibiotics = readData(format=\"csv\", fromPath=\"datasets-private/antibiotics/ghotb-isfahan.csv\")\n",
    "antibiotics = antibiotics.select([\"ATC\", \"LABEL\"]).withColumnsRenamed(colsMap={\"ATC\": \"atc_code\",\n",
    "                                                                               \"LABEL\": \"label\"})\n",
    "antibiotics.show(n=2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "dosage_form_words = [\"INJECTION\", \"CAPSULE\", \"SUSP\", \"TABLET\", \"SUSPENSION\", \"CREAM\"]\n",
    "\n",
    "def DosageForm(name: str):\n",
    "     if name == None:\n",
    "          return \"None\"\n",
    "     words: list[str] = name.split(\" \")\n",
    "     for word in words:\n",
    "          word = word.rstrip(\",\").upper()\n",
    "          for form in dosage_form_words:\n",
    "               if word == form:\n",
    "                    return form\n",
    "               \n",
    "findDosageFormUDF = udf(DosageForm, StringType())\n",
    "\n",
    "def FindDosageForm(dataframe: DataFrame, col_name: str) -> DataFrame:\n",
    "     return dataframe \\\n",
    "          .withColumn(\"dosage_form\", findDosageFormUDF(col(f\"{col_name}\"))) \\\n",
    "\n",
    "def countManufacturers(df: dict, year:int):\n",
    "     df: DataFrame = FindDosageForm(df, \"en_name\")\n",
    "     df = df.groupBy(\"atc_code\", \"dosage_form\").agg(countDistinct(\"brand_owner\").alias(f\"manufacturers_{year}\")) \n",
    "     return df\n",
    "        \n",
    "     #    print(f\"All manufacturers with their ATC codes: {result_df.count()}\")\n",
    "     #    print(\"-=-=-=-=-=-=-=-\")\n",
    "     # #    result_dfs.update(  {i: result_df}  )\n",
    "\n",
    "antibiotics_dossed = FindDosageForm(antibiotics, \"label\")\n",
    "for df_year in dataframes:\n",
    "     df = dataframes.get(df_year)\n",
    "     counted_df = countManufacturers(df, int(df_year))\n",
    "     result_df = counted_df.join(antibiotics_dossed, on=[\"atc_code\" ,\"dosage_form\"], how=\"inner\")\n",
    "     dataframes.update({df_year : result_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROWS: 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5433:====>           (2 + 5) / 7][Stage 5439:>               (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------------------+------------------+------------------+------------------+------------------+---------------------------------------------------------------------------+\n",
      "|atc_code|dosage_form|manufacturers_1398|manufacturers_1399|manufacturers_1400|manufacturers_1401|manufacturers_1402|label                                                                      |\n",
      "+--------+-----------+------------------+------------------+------------------+------------------+------------------+---------------------------------------------------------------------------+\n",
      "|J01DC02 |INJECTION  |NULL              |NULL              |NULL              |2                 |NULL              |NULL                                                                       |\n",
      "|J01GB06 |INJECTION  |3                 |3                 |3                 |3                 |3                 |AMIKACIN (AS SULFATE) INJECTION PARENTERAL 250 mg/1mL 2 mL                 |\n",
      "|J01GB06 |INJECTION  |3                 |3                 |3                 |3                 |3                 |AMIKACIN (AS SULFATE) INJECTION PARENTERAL 50 mg/1mL 2 mL                  |\n",
      "|J01CA04 |CAPSULE    |8                 |10                |8                 |8                 |7                 |AMOXICILLIN CAPSULE ORAL 250 mg                                            |\n",
      "|J01CA04 |CAPSULE    |8                 |10                |8                 |8                 |7                 |AMOXICILLIN CAPSULE ORAL 500 mg                                            |\n",
      "|J01CA04 |SUSPENSION |7                 |7                 |5                 |6                 |6                 |AMOXICILLIN POWDER, FOR SUSPENSION ORAL 125 mg/5mL 100 mL                  |\n",
      "|J01CA04 |SUSPENSION |7                 |7                 |5                 |6                 |6                 |AMOXICILLIN POWDER, FOR SUSPENSION ORAL 200 mg/5 mL 70 mL                  |\n",
      "|J01CA04 |SUSPENSION |7                 |7                 |5                 |6                 |6                 |AMOXICILLIN POWDER, FOR SUSPENSION ORAL 250 mg/5mL 100 mL                  |\n",
      "|J01CA04 |SUSPENSION |7                 |7                 |5                 |6                 |6                 |AMOXICILLIN POWDER, FOR SUSPENSION ORAL 400 mg/5 mL 70 mL                  |\n",
      "|J01CA04 |TABLET     |1                 |2                 |1                 |2                 |2                 |AMOXICILLIN TABLET ORAL 250 mg                                             |\n",
      "|J01CA04 |TABLET     |1                 |2                 |1                 |2                 |2                 |AMOXICILLIN TABLET ORAL 500 mg                                             |\n",
      "|J01CR01 |INJECTION  |2                 |2                 |2                 |2                 |2                 |AMPICILLIN / SULBACTAM INJECTION, POWDER, FOR SOLUTION PARENTERAL 1 g/0.5 g|\n",
      "|J01CR01 |INJECTION  |2                 |2                 |2                 |2                 |2                 |AMPICILLIN / SULBACTAM INJECTION, POWDER, FOR SOLUTION PARENTERAL 2 g/1 g  |\n",
      "|J01CA01 |INJECTION  |2                 |2                 |2                 |2                 |2                 |AMPICILLIN INJECTION, POWDER, FOR SOLUTION PARENTERAL 1 g                  |\n",
      "|J01CA01 |INJECTION  |2                 |2                 |2                 |2                 |2                 |AMPICILLIN INJECTION, POWDER, FOR SOLUTION PARENTERAL 250 mg               |\n",
      "|J01CA01 |INJECTION  |2                 |2                 |2                 |2                 |2                 |AMPICILLIN INJECTION, POWDER, FOR SOLUTION PARENTERAL 500 mg               |\n",
      "|J01CA01 |SUSPENSION |1                 |1                 |NULL              |NULL              |NULL              |AMPICILLIN POWDER, FOR SUSPENSION ORAL 125 mg/5 mL 100 mL                  |\n",
      "|J01CA01 |SUSPENSION |1                 |1                 |NULL              |NULL              |NULL              |AMPICILLIN POWDER, FOR SUSPENSION ORAL 250 mg/5 mL 100 mL                  |\n",
      "|J01FA10 |CAPSULE    |14                |17                |16                |14                |14                |AZITHROMYCIN CAPSULE ORAL 250 mg                                           |\n",
      "|J01FA10 |CAPSULE    |14                |17                |16                |14                |14                |AZITHROMYCIN CAPSULE ORAL 500 mg                                           |\n",
      "+--------+-----------+------------------+------------------+------------------+------------------+------------------+---------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = dataframes.get(\"1398\") \\\n",
    "    .join(dataframes.get(\"1399\").drop(\"label\"), on=[\"atc_code\", \"dosage_form\"], how=\"outer\") \\\n",
    "    .join(dataframes.get(\"1400\").drop(\"label\"), on=[\"atc_code\", \"dosage_form\"], how=\"outer\") \\\n",
    "    .join(dataframes.get(\"1401\").drop(\"label\"), on=[\"atc_code\", \"dosage_form\"], how=\"outer\") \\\n",
    "    .join(dataframes.get(\"1402\").drop(\"label\"), on=[\"atc_code\", \"dosage_form\"], how=\"outer\")\n",
    "\n",
    "df = df.select(\"atc_code\", \"dosage_form\", \"manufacturers_1398\",\n",
    "               \"manufacturers_1399\" , \"manufacturers_1400\" ,\n",
    "               \"manufacturers_1401\" , \"manufacturers_1402\" , \"label\") \\\n",
    "        .dropDuplicates([\"atc_code\", \"dosage_form\", \"label\"]) \\\n",
    "        .sort(\"label\")\n",
    "\n",
    "print(f\"ROWS: {df.count()}\")\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZeroHandler(input):\n",
    "    if input == None:\n",
    "        return 0\n",
    "    else:\n",
    "        return input\n",
    "    \n",
    "zeroHandlerUDF = udf(ZeroHandler, IntegerType())\n",
    "\n",
    "for df_year in dataframes:\n",
    "    df = df.withColumn(f\"{df_year}\", zeroHandlerUDF(col(f\"manufacturers_{df_year}\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array\n",
    "from pyspark.sql.types import FloatType\n",
    "import numpy as np\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "    \n",
    "def Var(array):\n",
    "    return float(np.var(array))/float(np.mean(array))\n",
    "\n",
    "varUDF = udf(Var, FloatType())\n",
    "\n",
    "years_columns = ['1398', '1399', '1400', '1401', '1402']\n",
    "\n",
    "df = df.withColumn(\"years_array\", array([col(x) for x in years_columns]))\n",
    "df = df.withColumn(\"variance\", varUDF(col(\"years_array\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+--------+\n",
      "|atc_code|variance  |cluster|category|\n",
      "+--------+----------+-------+--------+\n",
      "|J01CA01 |0.6       |0      |little  |\n",
      "|J01CA01 |0.6       |0      |little  |\n",
      "|J01FA10 |0.10666667|0      |little  |\n",
      "|J01FA10 |0.10666667|0      |little  |\n",
      "|J01FA10 |0.07619048|0      |little  |\n",
      "|J01FA10 |0.13333334|0      |little  |\n",
      "|J01FA10 |0.07619048|0      |little  |\n",
      "|J01FA10 |0.07619048|0      |little  |\n",
      "|J01FA10 |0.07619048|0      |little  |\n",
      "|J01FA10 |0.07619048|0      |little  |\n",
      "|J01FA10 |0.17704917|0      |little  |\n",
      "|J01FA10 |0.17704917|0      |little  |\n",
      "|J01CE01 |1.7       |2      |moderate|\n",
      "|J01CE01 |1.7       |2      |moderate|\n",
      "|J01CE01 |1.7       |2      |moderate|\n",
      "|J01DB01 |1.75      |2      |moderate|\n",
      "|J01DB01 |1.75      |2      |moderate|\n",
      "|J01DB01 |0.5777778 |0      |little  |\n",
      "|J01DB01 |0.5777778 |0      |little  |\n",
      "|J01DB04 |1.4689655 |2      |moderate|\n",
      "+--------+----------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assemble the variance into a feature vector\n",
    "assembler = VectorAssembler(inputCols=[\"variance\"], outputCol=\"variance_vec\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# Normalize the variance\n",
    "scaler = StandardScaler(inputCol=\"variance_vec\", outputCol=\"normalized_variance\", withMean=True, withStd=True)\n",
    "scaler_model = scaler.fit(df)\n",
    "df = scaler_model.transform(df)\n",
    "\n",
    "# Cluster the data\n",
    "k_mean = KMeans(k=3, seed=0, featuresCol=\"normalized_variance\", predictionCol=\"cluster\")\n",
    "model = k_mean.fit(df)\n",
    "df = model.transform(df)\n",
    "\n",
    "# Define cluster to category mapping\n",
    "cluster_mapping = {0: 'little', 1: 'most', 2: 'moderate'}\n",
    "\n",
    "# Convert mapping\n",
    "mapping_df = spark.createDataFrame(list(cluster_mapping.items()), [\"cluster\", \"category\"])\n",
    "df = df.join(mapping_df, \"cluster\")\n",
    "\n",
    "df.select(\"atc_code\", \"variance\", \"cluster\", \"category\").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final result...\n",
      "result page ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined data frames pages ...\n",
      "page 1398 ...\n",
      "page 1399 ...\n",
      "page 1400 ...\n",
      "page 1401 ...\n",
      "page 1402 ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "\n",
    "if save:\n",
    "    print(\"Saving final result...\")\n",
    "    with pd.ExcelWriter(\"datasets-private/result.xlsx\") as writer:\n",
    "        print(\"result page ...\")\n",
    "        df.drop(\"cluster\", \"1398\", \"1399\", \"1400\", \"1401\", \"1402\").toPandas().to_excel(writer, sheet_name=\"result\", index=True)\n",
    "        print(\"joined data frames pages ...\")\n",
    "        for i in range(1398, 1403):\n",
    "            print(f\"page {i} ...\")\n",
    "            dataframes.get(str(i)).toPandas().to_excel(writer, sheet_name=f\"{i}\", index=False)\n",
    "        print(\"Done\")\n",
    "else:\n",
    "    print(\"NOT SAVED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
